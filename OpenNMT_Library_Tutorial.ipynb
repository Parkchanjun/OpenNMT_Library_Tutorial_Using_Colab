{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenNMT_Library_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4HzdMCk6d3E",
        "colab_type": "text"
      },
      "source": [
        "***First Go to Runtime and  change the runtime type to GPU.***\n",
        "\n",
        "\n",
        "<br>\n",
        "Made by Chanjun Park (Korea University NLP&AI Lab)\n",
        "<br>\n",
        " Email: bcj1210@naver.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0KGIRzC6OCw",
        "colab_type": "text"
      },
      "source": [
        "GIT Clone the OpenNMT Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd9XZF9oT1-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6357fe09-7bbc-4da4-b6b5-80c971faa896"
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNMT-py'...\n",
            "remote: Enumerating objects: 15108, done.\u001b[K\n",
            "remote: Total 15108 (delta 0), reused 0 (delta 0), pack-reused 15108\u001b[K\n",
            "Receiving objects: 100% (15108/15108), 146.30 MiB | 30.99 MiB/s, done.\n",
            "Resolving deltas: 100% (10855/10855), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQ9WzD16pTZ",
        "colab_type": "text"
      },
      "source": [
        "Pip install<br>\n",
        "\n",
        "> Error : You must restart the runtime in order to use newly installed versions.<br>\n",
        "Solution : Click Restart Runtime => Redo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPX7MV9NOWdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "61efb41f-c6c1-4c88-d848-6e1654ec6ce1"
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.6/dist-packages (1.0.0rc2)\n",
            "Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: tqdm~=4.30.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (4.30.0)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.15.1)\n",
            "Requirement already satisfied: pyonmttok==1.*; platform_system == \"Linux\" in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.17.1)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->OpenNMT-py) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->OpenNMT-py) (1.17.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (41.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmEeInvh6xc-",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyEde_ObVKSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "b4fc4c79-0390-47ea-dcb5-16b2c635b466"
      },
      "source": [
        "!onmt_preprocess -train_src OpenNMT-py/data/src-train.txt -train_tgt OpenNMT-py/data/tgt-train.txt -valid_src OpenNMT-py/data/src-val.txt -valid_tgt OpenNMT-py/data/tgt-val.txt -save_data OpenNMT-py/data/data -src_vocab_size 10000 -tgt_vocab_size 10000"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-12-04 03:05:30,014 INFO] Extracting features...\n",
            "[2019-12-04 03:05:30,014 INFO]  * number of source features: 0.\n",
            "[2019-12-04 03:05:30,014 INFO]  * number of target features: 0.\n",
            "[2019-12-04 03:05:30,014 INFO] Building `Fields` object...\n",
            "[2019-12-04 03:05:30,014 INFO] Building & saving training data...\n",
            "[2019-12-04 03:05:30,046 INFO] Building shard 0.\n",
            "[2019-12-04 03:05:30,455 INFO]  * saving 0th train data shard to OpenNMT-py/data/data.train.0.pt.\n",
            "[2019-12-04 03:05:31,072 INFO]  * tgt vocab size: 10004.\n",
            "[2019-12-04 03:05:31,100 INFO]  * src vocab size: 10002.\n",
            "[2019-12-04 03:05:31,205 INFO] Building & saving validation data...\n",
            "[2019-12-04 03:05:31,278 INFO] Building shard 0.\n",
            "[2019-12-04 03:05:31,369 INFO]  * saving 0th valid data shard to OpenNMT-py/data/data.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6BFNDu561vu",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oST0x2JEU0MR",
        "colab_type": "code",
        "outputId": "8cec0472-9d6c-4f12-cd58-98626ad87af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import onmt\n",
        "import onmt.inputters\n",
        "import onmt.modules\n",
        "import onmt.utils\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.NOTSET)\n",
        "\n",
        "\"\"\"\n",
        "We begin by loading in the vocabulary for the model of interest. \n",
        "This will let us check vocab size and to get the special ids for padding\n",
        "\"\"\"\n",
        "\n",
        "vocab_fields = torch.load(\"OpenNMT-py/data/data.vocab.pt\") #vocab field 만들기\n",
        "\n",
        "src_text_field = vocab_fields[\"src\"].base_field #src field 만들기\n",
        "src_vocab = src_text_field.vocab\n",
        "src_padding = src_vocab.stoi[src_text_field.pad_token] #Padding\n",
        "\n",
        "tgt_text_field = vocab_fields['tgt'].base_field #tgt field 만들기\n",
        "tgt_vocab = tgt_text_field.vocab\n",
        "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token] #Padding\n",
        "\n",
        "\"\"\"\n",
        "Next we specify the core model itself. \n",
        "Here we will build a small model with an encoder and an attention based input feeding decoder. \n",
        "Both models will be RNNs and the encoder will be bidirectional\n",
        "\"\"\"\n",
        "\n",
        "emb_size = 100\n",
        "rnn_size = 500\n",
        "# Specify the core model.\n",
        "\n",
        "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
        "                                             word_padding_idx=src_padding) #src 임베딩\n",
        "\n",
        "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
        "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
        "                                   embeddings=encoder_embeddings) #인코더 \n",
        "\n",
        "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
        "                                             word_padding_idx=tgt_padding) #tgt 임베딩\n",
        "\n",
        "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
        "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
        "    rnn_type=\"LSTM\", embeddings=decoder_embeddings) #Decoder \n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #Device 설정 \n",
        "\n",
        "model = onmt.models.model.NMTModel(encoder, decoder) #모델 생성 \n",
        "model.to(device)#디바이스 올리기 \n",
        "\n",
        "# Specify the tgt word generator and loss computation module\n",
        "model.generator = nn.Sequential(\n",
        "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
        "    nn.LogSoftmax(dim=-1)).to(device) #제너레이터 부분 \n",
        "\n",
        "loss = onmt.utils.loss.NMTLossCompute(\n",
        "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
        "    generator=model.generator) #Loss 설정\n",
        "\n",
        "\"\"\"\n",
        "Now we set up the optimizer. \n",
        "Our wrapper around a core torch optim class handles learning rate updates and gradient normalization automatically.\n",
        "\"\"\"\n",
        "lr = 1\n",
        "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr) #옵티마이져\n",
        "optim = onmt.utils.optimizers.Optimizer(\n",
        "    torch_optimizer, learning_rate=lr, max_grad_norm=2) #옵티마이저\n",
        "\n",
        "\"\"\"\n",
        "Now we load the data from disk with the associated vocab fields. \n",
        "To iterate through the data itself we use a wrapper around a torchtext iterator class. \n",
        "We specify one for both the training and test data.\n",
        "\"\"\"\n",
        "\n",
        "# Load some data\n",
        "from itertools import chain\n",
        "\n",
        "train_data_file = \"OpenNMT-py/data/data.train.0.pt\" #학습데이터\n",
        "valid_data_file = \"OpenNMT-py/data/data.valid.0.pt\" #검증데이터 \n",
        "\n",
        "train_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[train_data_file],\n",
        "                                                     fields=vocab_fields,\n",
        "                                                     batch_size=50,\n",
        "                                                     batch_size_multiple=1,\n",
        "                                                     batch_size_fn=None,\n",
        "                                                     device=device,\n",
        "                                                     is_train=True,\n",
        "                                                     repeat=True,\n",
        "                                                     pool_factor=True#기존 소스 코드 변경\n",
        "                                                     ) #iterator 만들기\n",
        "\n",
        "valid_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[valid_data_file],\n",
        "                                                     fields=vocab_fields,\n",
        "                                                     batch_size=10,\n",
        "                                                     batch_size_multiple=1,\n",
        "                                                     batch_size_fn=None,\n",
        "                                                     device=device,\n",
        "                                                     is_train=False,\n",
        "                                                     repeat=False,\n",
        "                                                     pool_factor=True\n",
        "                                                     )\n",
        "\n",
        "\"\"\"\n",
        "Finally we train. Keeping track of the output requires a report manager.\n",
        "\"\"\"\n",
        "\n",
        "report_manager = onmt.utils.ReportMgr(\n",
        "    report_every=50, start_time=None, tensorboard_writer=None) #리포트 매니저\n",
        "\n",
        "trainer = onmt.Trainer(model=model,\n",
        "                       train_loss=loss,\n",
        "                       valid_loss=loss,\n",
        "                       optim=optim,\n",
        "                       report_manager=report_manager) #트레이너 생성 \n",
        "\n",
        "trainer.train(train_iter=train_iter,\n",
        "              train_steps=400,\n",
        "              valid_iter=valid_iter,\n",
        "              valid_steps=200) #실제 학습진행\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Start training loop and validate every 200 steps...\n",
            "INFO:root:Loading dataset from OpenNMT-py/data/data.train.0.pt\n",
            "INFO:root:number of examples: 10000\n",
            "INFO:root:Step 50/  400; acc:  12.00; ppl: 1720.04; xent: 7.45; lr: 1.00000; 4665/4628 tok/s;     12 sec\n",
            "INFO:root:Step 100/  400; acc:  14.31; ppl: 540.16; xent: 6.29; lr: 1.00000; 4781/4767 tok/s;     24 sec\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d0aa31d4a9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m               \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m               \u001b[0mvalid_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m               valid_steps=200) #실제 학습진행\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_iter, train_steps, save_checkpoint_steps, valid_iter, valid_steps)\u001b[0m\n\u001b[1;32m    241\u001b[0m             self._gradient_accumulation(\n\u001b[1;32m    242\u001b[0m                 \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 report_stats)\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_decay\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/trainer.py\u001b[0m in \u001b[0;36m_gradient_accumulation\u001b[0;34m(self, true_batches, normalization, total_stats, report_stats)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0mbptt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/models/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, lengths, bptt)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_bank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         dec_out, attns = self.decoder(tgt, memory_bank,\n\u001b[0;32m---> 47\u001b[0;31m                                       memory_lengths=lengths)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/decoders/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory_bank, memory_lengths, step)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         dec_state, dec_outs, attns = self._run_forward_pass(\n\u001b[0;32m--> 213\u001b[0;31m             tgt, memory_bank, memory_lengths=memory_lengths)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Update the state with the result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/decoders/decoder.py\u001b[0m in \u001b[0;36m_run_forward_pass\u001b[0;34m(self, tgt, memory_bank, memory_lengths)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0mmemory_bank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                     memory_lengths=memory_lengths)\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mattns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onmt/modules/global_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source, memory_bank, memory_lengths, coverage)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mconcat_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtarget_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mattn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"general\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mattn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWHLf6AB64hs",
        "colab_type": "text"
      },
      "source": [
        "Translating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zota2HXzYev-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import onmt.translate\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.NOTSET)\n",
        "\n",
        "src_reader = onmt.inputters.str2reader[\"text\"]\n",
        "tgt_reader = onmt.inputters.str2reader[\"text\"]\n",
        "\n",
        "scorer = onmt.translate.GNMTGlobalScorer(alpha=0.7, \n",
        "                                         beta=0., \n",
        "                                         length_penalty=\"avg\", \n",
        "                                         coverage_penalty=\"none\")\n",
        "\n",
        "gpu = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "translator = onmt.translate.Translator(model=model, \n",
        "                                       fields=vocab_fields, \n",
        "                                       src_reader=src_reader, \n",
        "                                       tgt_reader=tgt_reader, \n",
        "                                       global_scorer=scorer,\n",
        "                                       beam_size=1,\n",
        "                                       gpu=gpu) #트랜스레이터 생성 \n",
        "\n",
        "builder = onmt.translate.TranslationBuilder(data=torch.load(valid_data_file), \n",
        "                                            fields=vocab_fields) #빌더 생성 \n",
        "\n",
        "for batch in valid_iter:\n",
        "    trans_batch = translator.translate_batch(\n",
        "        batch=batch, src_vocabs=[src_vocab],\n",
        "        attn_debug=False) #번역진행\n",
        "    \n",
        "    translations = builder.from_batch(trans_batch)#배치만큼\n",
        "    for trans in translations:\n",
        "        print(trans.log(0))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}