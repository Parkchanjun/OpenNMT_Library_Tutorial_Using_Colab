{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenNMT_Library_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd9XZF9oT1-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPX7MV9NOWdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyEde_ObVKSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onmt_preprocess -train_src OpenNMT-py/data/src-train.txt -train_tgt OpenNMT-py/data/tgt-train.txt -valid_src OpenNMT-py/data/src-val.txt -valid_tgt OpenNMT-py/data/tgt-val.txt -save_data OpenNMT-py/data/data -src_vocab_size 10000 -tgt_vocab_size 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oST0x2JEU0MR",
        "colab_type": "code",
        "outputId": "89a9b99c-da3c-46bb-9222-23de8db32551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import onmt\n",
        "import onmt.inputters\n",
        "import onmt.modules\n",
        "import onmt.utils\n",
        "\n",
        "\"\"\"\n",
        "We begin by loading in the vocabulary for the model of interest. \n",
        "This will let us check vocab size and to get the special ids for padding\n",
        "\"\"\"\n",
        "\n",
        "vocab_fields = torch.load(\"OpenNMT-py/data/data.vocab.pt\") #vocab field 만들기\n",
        "\n",
        "src_text_field = vocab_fields[\"src\"].base_field #src field 만들기\n",
        "src_vocab = src_text_field.vocab\n",
        "src_padding = src_vocab.stoi[src_text_field.pad_token] #Padding\n",
        "\n",
        "tgt_text_field = vocab_fields['tgt'].base_field #tgt field 만들기\n",
        "tgt_vocab = tgt_text_field.vocab\n",
        "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token] #Padding\n",
        "\n",
        "\"\"\"\n",
        "Next we specify the core model itself. \n",
        "Here we will build a small model with an encoder and an attention based input feeding decoder. \n",
        "Both models will be RNNs and the encoder will be bidirectional\n",
        "\"\"\"\n",
        "\n",
        "emb_size = 100\n",
        "rnn_size = 500\n",
        "# Specify the core model.\n",
        "\n",
        "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
        "                                             word_padding_idx=src_padding) #src 임베딩\n",
        "\n",
        "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
        "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
        "                                   embeddings=encoder_embeddings) #인코더 \n",
        "\n",
        "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
        "                                             word_padding_idx=tgt_padding) #tgt 임베딩\n",
        "\n",
        "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
        "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
        "    rnn_type=\"LSTM\", embeddings=decoder_embeddings) #Decoder \n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #Device 설정 \n",
        "\n",
        "model = onmt.models.model.NMTModel(encoder, decoder) #모델 생성 \n",
        "model.to(device)#디바이스 올리기 \n",
        "\n",
        "# Specify the tgt word generator and loss computation module\n",
        "model.generator = nn.Sequential(\n",
        "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
        "    nn.LogSoftmax(dim=-1)).to(device) #제너레이터 부분 \n",
        "\n",
        "loss = onmt.utils.loss.NMTLossCompute(\n",
        "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
        "    generator=model.generator) #Loss 설정\n",
        "\n",
        "\"\"\"\n",
        "Now we set up the optimizer. \n",
        "Our wrapper around a core torch optim class handles learning rate updates and gradient normalization automatically.\n",
        "\"\"\"\n",
        "lr = 1\n",
        "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr) #옵티마이져\n",
        "optim = onmt.utils.optimizers.Optimizer(\n",
        "    torch_optimizer, learning_rate=lr, max_grad_norm=2) #옵티마이저\n",
        "\n",
        "\"\"\"\n",
        "Now we load the data from disk with the associated vocab fields. \n",
        "To iterate through the data itself we use a wrapper around a torchtext iterator class. \n",
        "We specify one for both the training and test data.\n",
        "\"\"\"\n",
        "\n",
        "# Load some data\n",
        "from itertools import chain\n",
        "\n",
        "train_data_file = \"OpenNMT-py/data/data.train.0.pt\" #학습데이터\n",
        "valid_data_file = \"OpenNMT-py/data/data.valid.0.pt\" #검증데이터 \n",
        "\n",
        "train_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[train_data_file],\n",
        "                                                     fields=vocab_fields,\n",
        "                                                     batch_size=50,\n",
        "                                                     batch_size_multiple=1,\n",
        "                                                     batch_size_fn=None,\n",
        "                                                     device=device,\n",
        "                                                     is_train=True,\n",
        "                                                     repeat=True,\n",
        "                                                     pool_factor=True#기존 소스 코드 변경\n",
        "                                                     ) #iterator 만들기\n",
        "\n",
        "valid_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[valid_data_file],\n",
        "                                                     fields=vocab_fields,\n",
        "                                                     batch_size=10,\n",
        "                                                     batch_size_multiple=1,\n",
        "                                                     batch_size_fn=None,\n",
        "                                                     device=device,\n",
        "                                                     is_train=False,\n",
        "                                                     repeat=False,\n",
        "                                                     pool_factor=True\n",
        "                                                     )\n",
        "\n",
        "\"\"\"\n",
        "Finally we train. Keeping track of the output requires a report manager.\n",
        "\"\"\"\n",
        "\n",
        "report_manager = onmt.utils.ReportMgr(\n",
        "    report_every=50, start_time=None, tensorboard_writer=None) #리포트 매니저\n",
        "\n",
        "trainer = onmt.Trainer(model=model,\n",
        "                       train_loss=loss,\n",
        "                       valid_loss=loss,\n",
        "                       optim=optim,\n",
        "                       report_manager=report_manager) #트레이너 생성 \n",
        "\n",
        "trainer.train(train_iter=train_iter,\n",
        "              train_steps=400,\n",
        "              valid_iter=valid_iter,\n",
        "              valid_steps=200) #실제 학습진행\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<onmt.utils.statistics.Statistics at 0x7f457ca57780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zota2HXzYev-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import onmt.translate\n",
        "\n",
        "src_reader = onmt.inputters.str2reader[\"text\"]\n",
        "tgt_reader = onmt.inputters.str2reader[\"text\"]\n",
        "\n",
        "scorer = onmt.translate.GNMTGlobalScorer(alpha=0.7, \n",
        "                                         beta=0., \n",
        "                                         length_penalty=\"avg\", \n",
        "                                         coverage_penalty=\"none\")\n",
        "\n",
        "gpu = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "translator = onmt.translate.Translator(model=model, \n",
        "                                       fields=vocab_fields, \n",
        "                                       src_reader=src_reader, \n",
        "                                       tgt_reader=tgt_reader, \n",
        "                                       global_scorer=scorer,\n",
        "                                       beam_size=1,\n",
        "                                       gpu=gpu) #트랜스레이터 생성 \n",
        "\n",
        "builder = onmt.translate.TranslationBuilder(data=torch.load(valid_data_file), \n",
        "                                            fields=vocab_fields) #빌더 생성 \n",
        "\n",
        "for batch in valid_iter:\n",
        "    trans_batch = translator.translate_batch(\n",
        "        batch=batch, src_vocabs=[src_vocab],\n",
        "        attn_debug=False) #번역진행\n",
        "    \n",
        "    translations = builder.from_batch(trans_batch)#배치만큼\n",
        "    for trans in translations:\n",
        "        print(trans.log(0))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}